{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Survival Analysis: Based on Gradient Boosting Machine(GBM)\n",
    "\n",
    "The tutorial give typical workflow of Gradient Boosting Desicion Tree-based survival analysis including data-preprocessing, model selection and traning&validation, uses R package `gbm`.\n",
    "\n",
    "Formally, it can be listed by:\n",
    "1. Data Preprocessing\n",
    "  - convert variables\n",
    "  - load training and test set\n",
    "2. Model Selection\n",
    "  - cross validation\n",
    "  - tune parameters\n",
    "3. Traning&Validation\n",
    "  - train gbm model\n",
    "  - measure CI on testset\n",
    "  - survival rates on time of interest\n",
    "  \n",
    "The best suggestion about usage of `gbm` is official documentation named **\"Generalized Boosted Models:A guide to the gbm package\"**. Here, I summary some points related to usage of the package and SA, and disscussion of options to gbm that most users will need to change or tune.\n",
    "\n",
    "### 1. Loss Function\n",
    "\n",
    "`distribution` is corresponding to loss function and application. Here, the option `coxph` indicating SA should be selected.\n",
    "\n",
    "### 2. Model Fitting\n",
    "\n",
    "`shrinkage` and `n.trees` are mostly related to performance, so those should be tuned carefully.\n",
    "\n",
    "As recommended by author of `gbm`, it is generally the case that for small shrinkage parameters, 0.001 for example.\n",
    ">  My rule of thumb is to set shrinkage as small as possible while still being able to fit the model in a reasonable amount of time and storage. I usually aim for 3,000 to 10,000 iterations with shrinkage rates between 0.01 and 0.001.\n",
    "\n",
    "### 3. The Optimal Number of Iterations\n",
    "\n",
    "`gbm` offers three methods for estimating the optimal number of iterations after the gbm model has been fit, an independent test set (`test`), out-of-bag estimation (`OOB`), and v-fold cross validation (`cv`). The function `gbm.perf` computes the iteration estimate.\n",
    "\n",
    "Among these methods for estimating `n.trees`, **V-Fold Cross Validation** is the best choice.\n",
    "> My recommendation is to use 5- or 10-fold cross validation if you can afford the computing time. Otherwise you may choose among the other options, knowing that OOB is conservative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0 - Load library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'gbm' was built under R version 3.5.1\"Loaded gbm 2.1.4\n"
     ]
    }
   ],
   "source": [
    "library('survival')\n",
    "library('gbm')\n",
    "# set random state\n",
    "set.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 137 \n",
      "Columns of dataset: trt celltype time status karno diagtime age prior \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trt</th><th scope=col>celltype</th><th scope=col>time</th><th scope=col>status</th><th scope=col>karno</th><th scope=col>diagtime</th><th scope=col>age</th><th scope=col>prior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>1  </td><td> 72</td><td>1  </td><td>60 </td><td> 7 </td><td>69 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>411</td><td>1  </td><td>70 </td><td> 5 </td><td>64 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>228</td><td>1  </td><td>60 </td><td> 3 </td><td>38 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>126</td><td>1  </td><td>60 </td><td> 9 </td><td>63 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>118</td><td>1  </td><td>70 </td><td>11 </td><td>65 </td><td>10 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " trt & celltype & time & status & karno & diagtime & age & prior\\\\\n",
       "\\hline\n",
       "\t 1   & 1   &  72 & 1   & 60  &  7  & 69  &  0 \\\\\n",
       "\t 1   & 1   & 411 & 1   & 70  &  5  & 64  & 10 \\\\\n",
       "\t 1   & 1   & 228 & 1   & 60  &  3  & 38  &  0 \\\\\n",
       "\t 1   & 1   & 126 & 1   & 60  &  9  & 63  & 10 \\\\\n",
       "\t 1   & 1   & 118 & 1   & 70  & 11  & 65  & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trt | celltype | time | status | karno | diagtime | age | prior | \n",
       "|---|---|---|---|---|\n",
       "| 1   | 1   |  72 | 1   | 60  |  7  | 69  |  0  | \n",
       "| 1   | 1   | 411 | 1   | 70  |  5  | 64  | 10  | \n",
       "| 1   | 1   | 228 | 1   | 60  |  3  | 38  |  0  | \n",
       "| 1   | 1   | 126 | 1   | 60  |  9  | 63  | 10  | \n",
       "| 1   | 1   | 118 | 1   | 70  | 11  | 65  | 10  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trt celltype time status karno diagtime age prior\n",
       "1 1   1         72  1      60     7       69   0   \n",
       "2 1   1        411  1      70     5       64  10   \n",
       "3 1   1        228  1      60     3       38   0   \n",
       "4 1   1        126  1      60     9       63  10   \n",
       "5 1   1        118  1      70    11       65  10   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(veteran, package = \"randomForestSRC\")\n",
    "cat(\"Number of samples:\", nrow(veteran), \"\\n\")\n",
    "cat(\"Columns of dataset:\", colnames(veteran), \"\\n\")\n",
    "veteran[c(1:5), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the data and create a training subset.\n",
    "train <- sample(1:nrow(veteran), round(nrow(veteran) * 0.80))\n",
    "data_train <- veteran[train, ]\n",
    "data_test <- veteran[-train, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 - Model Training & Evaluation\n",
    "\n",
    "We will pass arguments to object `gbm` for training robust model after completing hyperparameters tuning in step2, and then validate our fitted model using test set.\n",
    "\n",
    "Here, evaluation and more in this section includes:\n",
    "\n",
    "- calculating CI metrics\n",
    "- calculating survival function on specified time\n",
    "- saving result as file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 - Model Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] 7.452676 7.411549 7.323226 7.283217 7.242676 7.213281 7.155838 7.141298\n",
      "  [9] 7.117086 7.100367 7.079169 7.065628 7.046587 7.039139 7.035529 7.025156\n",
      " [17] 7.013004 6.998314 6.994975 6.980497 6.971504 6.964180 6.957446 6.955998\n",
      " [25] 6.943020 6.936833 6.931849 6.927928 6.918406 6.912547 6.909226 6.903453\n",
      " [33] 6.894153 6.899430 6.891607 6.885760 6.880229 6.875630 6.871242 6.867023\n",
      " [41] 6.859555 6.854401 6.852603 6.848217 6.843824 6.841187 6.837437 6.829515\n",
      " [49] 6.828534 6.825406 6.823117 6.821197 6.818626 6.818113 6.814419 6.812023\n",
      " [57] 6.807420 6.803212 6.800789 6.797621 6.798241 6.797777 6.796752 6.795991\n",
      " [65] 6.794354 6.790968 6.789161 6.788353 6.782757 6.778768 6.774355 6.768779\n",
      " [73] 6.766592 6.764387 6.762682 6.754721 6.753915 6.751372 6.746385 6.746444\n",
      " [81] 6.744177 6.741354 6.739005 6.736487 6.733526 6.735000 6.732901 6.728538\n",
      " [89] 6.726291 6.726717 6.728572 6.725986 6.725578 6.721763 6.726369 6.724885\n",
      " [97] 6.720713 6.720718 6.720603 6.716355\n"
     ]
    }
   ],
   "source": [
    "# using training set fits gbm model\n",
    "model <- gbm(Surv(time, status) ~ .,\n",
    "             distribution='coxph',\n",
    "             data=data_train)\n",
    "# values of loss function on training set for each tree\n",
    "print(model$train.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a vector of prediction on n.trees indicting log hazard scale.f(x)\n",
    "pred.train <- predict(model, data_train, n.trees = 100)\n",
    "pred.test <- predict(model, data_test, n.trees = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - CI (concordance index)\n",
    "We can get $\\text{CI}$(concordance index) by function `rcorr.cens` from package `Hmisc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.76556420233463</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.531128404669261</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.0481624035041144</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>110</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>102</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>11308</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>8657</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>626</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.76556420233463\n",
       "\\item[Dxy] 0.531128404669261\n",
       "\\item[S.D.] 0.0481624035041144\n",
       "\\item[n] 110\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 102\n",
       "\\item[Relevant Pairs] 11308\n",
       "\\item[Concordant] 8657\n",
       "\\item[Uncertain] 626\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.76556420233463Dxy\n",
       ":   0.531128404669261S.D.\n",
       ":   0.0481624035041144n\n",
       ":   110missing\n",
       ":   0uncensored\n",
       ":   102Relevant Pairs\n",
       ":   11308Concordant\n",
       ":   8657Uncertain\n",
       ":   626\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "  7.655642e-01   5.311284e-01   4.816240e-02   1.100000e+02   0.000000e+00 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "  1.020000e+02   1.130800e+04   8.657000e+03   6.260000e+02 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.train, Surv(data_train$time, data_train$status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>C Index</dt>\n",
       "\t\t<dd>0.648203592814371</dd>\n",
       "\t<dt>Dxy</dt>\n",
       "\t\t<dd>0.296407185628742</dd>\n",
       "\t<dt>S.D.</dt>\n",
       "\t\t<dd>0.145749919576285</dd>\n",
       "\t<dt>n</dt>\n",
       "\t\t<dd>27</dd>\n",
       "\t<dt>missing</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>uncensored</dt>\n",
       "\t\t<dd>26</dd>\n",
       "\t<dt>Relevant Pairs</dt>\n",
       "\t\t<dd>668</dd>\n",
       "\t<dt>Concordant</dt>\n",
       "\t\t<dd>433</dd>\n",
       "\t<dt>Uncertain</dt>\n",
       "\t\t<dd>32</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[C Index] 0.648203592814371\n",
       "\\item[Dxy] 0.296407185628742\n",
       "\\item[S.D.] 0.145749919576285\n",
       "\\item[n] 27\n",
       "\\item[missing] 0\n",
       "\\item[uncensored] 26\n",
       "\\item[Relevant Pairs] 668\n",
       "\\item[Concordant] 433\n",
       "\\item[Uncertain] 32\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "C Index\n",
       ":   0.648203592814371Dxy\n",
       ":   0.296407185628742S.D.\n",
       ":   0.145749919576285n\n",
       ":   27missing\n",
       ":   0uncensored\n",
       ":   26Relevant Pairs\n",
       ":   668Concordant\n",
       ":   433Uncertain\n",
       ":   32\n",
       "\n"
      ],
      "text/plain": [
       "       C Index            Dxy           S.D.              n        missing \n",
       "     0.6482036      0.2964072      0.1457499     27.0000000      0.0000000 \n",
       "    uncensored Relevant Pairs     Concordant      Uncertain \n",
       "    26.0000000    668.0000000    433.0000000     32.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hmisc::rcorr.cens(-pred.test, Surv(data_test$time, data_test$status))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 - Survival function\n",
    "\n",
    "`gbm` offers method `basehaz.gbm` to estimate the cumulative baseline hazard function $\\int_0^{t}\\lambda(z)dz$. Since survival function can be estimated by:\n",
    "$$\n",
    "s(t|X)=exp{\\{-\\ e^{f(X)}\\int_0^{t}\\lambda(z)dz\\}}\n",
    "$$\n",
    "\n",
    "$f(X)$ is prediction of `gbm`, which is equal to log-hazard proportion.\n",
    "So we can get survival function of individuals easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sepecify time of interest\n",
    "time.interest <- sort(unique(data_train$time[data_train$status==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the cumulative baseline hazard function using training data\n",
    "basehaz.cum <- basehaz.gbm(data_train$time, data_train$status, pred.train, t.eval = time.interest, cumulative = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For individual $i$ in test set, estimation of survival function is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "surf.i <- exp(-exp(pred.test[1])*basehaz.cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 9.944968e-01 9.917216e-01 9.888655e-01 9.801236e-01 9.677340e-01\n",
      " [6] 9.613012e-01 9.579700e-01 9.546404e-01 9.479611e-01 9.444907e-01\n",
      "[11] 9.409351e-01 9.300652e-01 9.259765e-01 9.176874e-01 9.131956e-01\n",
      "[16] 9.040865e-01 8.945661e-01 8.894424e-01 8.842690e-01 8.733314e-01\n",
      "[21] 8.623517e-01 8.568161e-01 8.511813e-01 8.453023e-01 8.393870e-01\n",
      "[26] 8.334773e-01 8.275762e-01 8.214120e-01 8.146979e-01 7.933158e-01\n",
      "[31] 7.776145e-01 7.694756e-01 7.532388e-01 7.449990e-01 7.367171e-01\n",
      "[36] 7.277190e-01 7.186409e-01 7.091510e-01 6.899998e-01 6.792196e-01\n",
      "[41] 6.680370e-01 6.567616e-01 6.451084e-01 6.333093e-01 6.083990e-01\n",
      "[46] 5.953123e-01 5.815242e-01 5.676897e-01 5.540396e-01 5.273443e-01\n",
      "[51] 5.117445e-01 4.962266e-01 4.807583e-01 4.652502e-01 4.496305e-01\n",
      "[56] 4.339541e-01 4.168827e-01 3.988288e-01 3.802071e-01 3.616559e-01\n",
      "[61] 3.429259e-01 3.226654e-01 3.020986e-01 2.815642e-01 2.610981e-01\n",
      "[66] 2.394407e-01 2.176524e-01 1.962988e-01 1.740657e-01 1.517649e-01\n",
      "[71] 1.314447e-01 1.080781e-01 8.437315e-02 6.428244e-02 4.479928e-02\n",
      "[76] 2.888401e-02 1.644502e-02 7.877202e-03 2.284930e-03 5.528885e-05\n"
     ]
    }
   ],
   "source": [
    "print(surf.i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of survival rate of all at specified time is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Rate of all at time 15 [1] 0.9444907 0.9675000 0.8151207 0.8625493 0.9496626 0.9587409 0.6214935\n",
      " [8] 0.9418253 0.9042441 0.9435269 0.9338808 0.7847206 0.9073920 0.9709306\n",
      "[15] 0.9841972 0.9329900 0.4770597 0.5935586 0.9068123 0.9495933 0.9199242\n",
      "[22] 0.9396928 0.5367361 0.8560934 0.9410605 0.9146667 0.9396928\n"
     ]
    }
   ],
   "source": [
    "specif.time <- time.interest[10]\n",
    "cat(\"Survival Rate of all at time\", specif.time, \"\\n\")\n",
    "surv.rate <- exp(-exp(pred.test)*basehaz.cum[10])\n",
    "print(surv.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 - Saving as file\n",
    "\n",
    "Here, we concate test data and prediction, survival rate, and then convert it to csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_test <- data_test\n",
    "# predicted outcome for test set\n",
    "res_test$pred <- pred.test\n",
    "res_test$survival_rate <- surv.rate\n",
    "# Save data\n",
    "write.csv(res_test, file = \"result_gbm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
