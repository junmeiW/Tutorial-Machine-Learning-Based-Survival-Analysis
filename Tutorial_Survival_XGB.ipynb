{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival Analysis: Based on eXtreme Gradient Boosting(XGB)\n",
    "\n",
    "The tutorial give typical workflow of eXtreme Gradient Boosting-based survival analysis including data-preprocessing, model selection and traning&validation, uses **R package** `xgboost`.\n",
    "\n",
    "Formally, it can be listed by:\n",
    "1. Data Preprocessing\n",
    "  - convert variables\n",
    "  - load training and test set\n",
    "2. Model Selection\n",
    "  - cross validation\n",
    "  - tune parameters\n",
    "3. Traning&Validation\n",
    "  - train gbm model\n",
    "  - measure CI on testset\n",
    "  - survival rates on time of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept and Related\n",
    "\n",
    "#### Concept of coxph\n",
    "Under assumption of cox proportional hazard model, there is:\n",
    "$$h(t|x) = h_0(t) \\cdot e^{f(x)}$$\n",
    "$f(x)$ is called **Hazard Ratio**.\n",
    "\n",
    "Given the observation $\\{(X_i,T_i,E_i)|i=1,\\dots ,n \\}$, the log partial likelihood function is:\n",
    "$$\n",
    "\\mathcal L=-\\sum_{i\\ :\\ E_i=1}\\bigl(f(x_i)-log\\sum_{j\\in \\mathcal R(i)}e^{f(x_j)}\\bigr) \\\\\n",
    "\\mathcal R(i)=\\{j|T_j\\ge T_i\\}\n",
    "$$\n",
    "If there is ties at time of death, the corresponding log partial likelihood function is:\n",
    "$$\n",
    "\\mathcal L=-\\sum_{i=1}^{k}\\bigl(\\sum_{j\\in \\mathcal q(i)}f(x_j)-d_i*log\\sum_{j\\in \\mathcal R(i)}e^{f(x_j)}\\bigr) \\\\\n",
    "k = \\big|\\text{unique}(\\{T_i|E_i=1\\})\\big| \\\\\n",
    "\\mathcal R(i)=\\{j|T_j\\ge T_i\\} \\\\\n",
    "\\mathcal q(i)=\\{j|T_j=T_i, E_i=1\\} \\\\\n",
    "d_i = \\vert q(i) \\vert\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step0 - Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'gbm' was built under R version 3.5.1\"Loaded gbm 2.1.4\n"
     ]
    }
   ],
   "source": [
    "library('survival')\n",
    "library('gbm')\n",
    "# set random state\n",
    "set.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 137 \n",
      "Columns of dataset: trt celltype time status karno diagtime age prior \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trt</th><th scope=col>celltype</th><th scope=col>time</th><th scope=col>status</th><th scope=col>karno</th><th scope=col>diagtime</th><th scope=col>age</th><th scope=col>prior</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1  </td><td>1  </td><td> 72</td><td>1  </td><td>60 </td><td> 7 </td><td>69 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>411</td><td>1  </td><td>70 </td><td> 5 </td><td>64 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>228</td><td>1  </td><td>60 </td><td> 3 </td><td>38 </td><td> 0 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>126</td><td>1  </td><td>60 </td><td> 9 </td><td>63 </td><td>10 </td></tr>\n",
       "\t<tr><td>1  </td><td>1  </td><td>118</td><td>1  </td><td>70 </td><td>11 </td><td>65 </td><td>10 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " trt & celltype & time & status & karno & diagtime & age & prior\\\\\n",
       "\\hline\n",
       "\t 1   & 1   &  72 & 1   & 60  &  7  & 69  &  0 \\\\\n",
       "\t 1   & 1   & 411 & 1   & 70  &  5  & 64  & 10 \\\\\n",
       "\t 1   & 1   & 228 & 1   & 60  &  3  & 38  &  0 \\\\\n",
       "\t 1   & 1   & 126 & 1   & 60  &  9  & 63  & 10 \\\\\n",
       "\t 1   & 1   & 118 & 1   & 70  & 11  & 65  & 10 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trt | celltype | time | status | karno | diagtime | age | prior | \n",
       "|---|---|---|---|---|\n",
       "| 1   | 1   |  72 | 1   | 60  |  7  | 69  |  0  | \n",
       "| 1   | 1   | 411 | 1   | 70  |  5  | 64  | 10  | \n",
       "| 1   | 1   | 228 | 1   | 60  |  3  | 38  |  0  | \n",
       "| 1   | 1   | 126 | 1   | 60  |  9  | 63  | 10  | \n",
       "| 1   | 1   | 118 | 1   | 70  | 11  | 65  | 10  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trt celltype time status karno diagtime age prior\n",
       "1 1   1         72  1      60     7       69   0   \n",
       "2 1   1        411  1      70     5       64  10   \n",
       "3 1   1        228  1      60     3       38   0   \n",
       "4 1   1        126  1      60     9       63  10   \n",
       "5 1   1        118  1      70    11       65  10   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(veteran, package = \"randomForestSRC\")\n",
    "cat(\"Number of samples:\", nrow(veteran), \"\\n\")\n",
    "cat(\"Columns of dataset:\", colnames(veteran), \"\\n\")\n",
    "veteran[c(1:5), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample the data and create a training subset.\n",
    "train <- sample(1:nrow(veteran), round(nrow(veteran) * 0.80))\n",
    "data_train <- veteran[train, ]\n",
    "data_test <- veteran[-train, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2 - Model Selection\n",
    "\n",
    "The hyperparameters should be tuned as follows:\n",
    "- eta : learning rate\n",
    "- max_depth : maximum depth of a tree\n",
    "- min_child_weight: minimum sum of instance weight(hessian) needed in a child\n",
    "- subsample: subsample ratio of the training instance\n",
    "- colsample_bytree: subsample ratio of columns when constructing each tree\n",
    "- gamma: minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "- alpha: L1-Regularization of instance weight items\n",
    "- labmda: L2-Regularization of instance weight items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3 - Model Training & Evaluation\n",
    "\n",
    "We will pass arguments to object `xgboost` for training robust model after completing hyperparameters tuning in step2, and then validate our fitted model using test set.\n",
    "\n",
    "Here, evaluation and more in this section includes:\n",
    "\n",
    "- calculating CI metrics\n",
    "- calculating survival function on specified time\n",
    "- saving result as file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 - Model Training & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
